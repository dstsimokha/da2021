{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sublime-minimum",
   "metadata": {},
   "source": [
    "[source 1](https://towardsdatascience.com/fitting-mlr-and-binary-logistic-regression-using-python-research-oriented-modeling-dcc22f1f0edf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worldwide-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm       \n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rc(\"figure\", figsize=(16,8))\n",
    "plt.rc(\"font\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "velvet-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dimensional-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rank'] = [str(i) for i in df['rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "serial-spotlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa rank\n",
       "0      0  380  3.61    3\n",
       "1      1  660  3.67    3\n",
       "2      1  800  4.00    1\n",
       "3      1  640  3.19    4\n",
       "4      0  520  2.93    4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-drill",
   "metadata": {},
   "source": [
    "# 1. Predict admission by the results of GPA and GRE tests and the rank of the university."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "straight-guarantee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573147\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  admit   No. Observations:                  400\n",
      "Model:                          Logit   Df Residuals:                      394\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Mon, 01 Feb 2021   Pseudo R-squ.:                 0.08292\n",
      "Time:                        20:55:05   Log-Likelihood:                -229.26\n",
      "converged:                       True   LL-Null:                       -249.99\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.578e-08\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -3.9900      1.140     -3.500      0.000      -6.224      -1.756\n",
      "rank[T.2]     -0.6754      0.316     -2.134      0.033      -1.296      -0.055\n",
      "rank[T.3]     -1.3402      0.345     -3.881      0.000      -2.017      -0.663\n",
      "rank[T.4]     -1.5515      0.418     -3.713      0.000      -2.370      -0.733\n",
      "gpa            0.8040      0.332      2.423      0.015       0.154       1.454\n",
      "gre            0.0023      0.001      2.070      0.038       0.000       0.004\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "model = logit(formula='admit ~ gpa + gre + rank', data=df).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-resort",
   "metadata": {},
   "source": [
    "# 2. Interpret the coefficients. Which are significant? Which are positive/negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-graphic",
   "metadata": {},
   "source": [
    "## Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "celtic-aspect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    True\n",
       "rank[T.2]    True\n",
       "rank[T.3]    True\n",
       "rank[T.4]    True\n",
       "gpa          True\n",
       "gre          True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pvalues < 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-skirt",
   "metadata": {},
   "source": [
    "All coefficients are **significant** as can be seen from their p-values which all are lower than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "trying-prayer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.019\n",
       "rank[T.2]    0.509\n",
       "rank[T.3]    0.262\n",
       "rank[T.4]    0.212\n",
       "gpa          2.235\n",
       "gre          1.002\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Odds Ratio\n",
    "round(np.exp(model.params), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-turkey",
   "metadata": {},
   "source": [
    "- **rank=2**: increase to *second* rank multiplies odds of admission by **0.509** times\n",
    "- **rank=3**: increase to *third* rank multiplies odds of admission by **0.262** times\n",
    "- **rank=4**: increase to *fourth* rank multiplies odds of admission by **0.212** times\n",
    "\n",
    "\n",
    "- **gpa**: increase in one unit of *gpa* multiplies odds of admission by **2.235** times\n",
    "- **gre**: increase in one unit of *gre* multiplies odds of admission by **1.002** times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "incident-document",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Marginal Effects</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>  <td>admit</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>         <td>dydx</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>At:</th>            <td>overall</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <th></th>         <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank[T.2]</th> <td>   -0.1314</td> <td>    0.060</td> <td>   -2.184</td> <td> 0.029</td> <td>   -0.249</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank[T.3]</th> <td>   -0.2608</td> <td>    0.062</td> <td>   -4.176</td> <td> 0.000</td> <td>   -0.383</td> <td>   -0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank[T.4]</th> <td>   -0.3019</td> <td>    0.076</td> <td>   -3.956</td> <td> 0.000</td> <td>   -0.451</td> <td>   -0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>       <td>    0.1564</td> <td>    0.063</td> <td>    2.485</td> <td> 0.013</td> <td>    0.033</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>       <td>    0.0004</td> <td>    0.000</td> <td>    2.107</td> <td> 0.035</td> <td> 3.07e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "        Logit Marginal Effects       \n",
       "=====================================\n",
       "Dep. Variable:                  admit\n",
       "Method:                          dydx\n",
       "At:                           overall\n",
       "==============================================================================\n",
       "                dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "rank[T.2]     -0.1314      0.060     -2.184      0.029      -0.249      -0.013\n",
       "rank[T.3]     -0.2608      0.062     -4.176      0.000      -0.383      -0.138\n",
       "rank[T.4]     -0.3019      0.076     -3.956      0.000      -0.451      -0.152\n",
       "gpa            0.1564      0.063      2.485      0.013       0.033       0.280\n",
       "gre            0.0004      0.000      2.107      0.035    3.07e-05       0.001\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average Marginal Effects\n",
    "model.get_margeff().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-retrieval",
   "metadata": {},
   "source": [
    "- **rank=2**: increase to *second* rank **decreases** the probability of admission by **13.14%**\n",
    "- **rank=3**: increase to *third* rank **decreases** the probability of admission by **26.08%**\n",
    "- **rank=4**: increase to *fourth* rank **decreases** the probability of admission by **30.19%**\n",
    "\n",
    "\n",
    "- **gpa**: increase in one unit of *gpa* **increases** the probability of admission by **15.64%**\n",
    "- **gre**: increase in one unit of *gre* **increases** the probability of admission by **0.04%**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-practitioner",
   "metadata": {},
   "source": [
    "As can be seen from the odds ratios and AMEs increasing in school **rank affect negatively** on admission probability and increasing in **GPA & GRA affect positively** on admission probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-trade",
   "metadata": {},
   "source": [
    "# 3. Test how the model fits the data. Find pseudo R2 and PCP (ePCP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "respected-selection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pseudo R-squ.:      0.08292\n"
     ]
    }
   ],
   "source": [
    "print(model.summary().tables[0][3][2], model.summary().tables[0][3][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-spring",
   "metadata": {},
   "source": [
    "Pseudo R-squared is **lower** than 0.1 which is not enough for considering model as good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "apart-raleigh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum([round(i) for i in model.predict()]==df.admit)/len(df))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-portfolio",
   "metadata": {},
   "source": [
    "Our model have **71** percent of corrected predicted values! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
